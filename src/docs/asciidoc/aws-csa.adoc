
https://interactive.linuxacademy.com/diagrams/AWSCSA.html

== Architecture 101

=== Registering

Root user

MFA - Multi-Factor Authentication
Can use Authy or Google Authenticator

Account types:

* professional
* personal

Support plans:

* free
* developer
  ** for early adoption, testing and development
  ** email access to AWS Support during business hours
  ** 1 primary contact can open an unlimited number of support cases
  ** 12-hour response time for nonproduction systems
* business
  ** for production workloads and business-critical dependencies
  ** 24/7 chat, phone, and email access to AWS Support
  ** unlimited contacts can open an unlimited number of
     support cases
  ** 1-hour response time for production systems

Creating a billing alarm in - cloudwatch


== Access Management Basics

* Principal - a person or application that can make an authenticated
  or anonymous request to perform an action on system.
* Authentication - the process of authenticating a principal against
  an identity. This could be via username and password or API keys.
* Identity - objects that require authentication and are authorized
  to access resources
* Authorization - the process of checking and allowing or denying
  access to a resource for an identity

=== Shared Responsibility Model

Responsibilities:

* AWS - security *OF* the cloud
* You - security *IN* the cloud
  ** Encryption at rest and in transit
  ** Network protection
  ** OS, Network and firewall config
  ** Platform, Application, IAM
  ** Customer Data

=== Service models

* IaaS - EC2
* PaaS - only Application and Data layer
* Saas - Netflix, Gmail

System stack:

* Data Center
* Network and storage
* Host/Servers
* Virtualization
* Operating System
* Runtime
* Application
* Data

=== High Availability and Fault Tolerance

High Availability::
  hardware, software, and configuration allowing a system to
  *recover quickly* from failure

Fault Tolerance::
  System designed to *operate through a failure* with
  *no user impact*. More expensive and complex to achieve.

=== Disaster Recovery

Recovery Point Objective (RPO)::
  How much a business can tolerate to lose, experssed in *time*.
  The maximum time between a failure and the last successful backup.

Recovery Time Objective (RTO)::
  The maximum amount of time a system can be *down*.
  How long a solution takes to *recover*.

=== Scaling

*Vertical scaling* is achieved by adding additional resources
in the form of CPU or memory to an existing machine.
By doing so, the machine is able to service additional customers
or perform compute tasks quicker. Eventually, **maximum
machine sizes** will constrain your ability to scale - either
**technically** or from a **cost** perspective.

**Horizontal scaling** is achieved by adding additional machines
into a pool of resources, each of which provide the same service.
Horizontal scaling suffers none of the size limitations of
vertical scaling and can scale to nearly infinite levels but requires
application support to scale effectively.

=== Tiered application

* presentation tier
* logic tier
* data tier

=== Encryption

Types:

* symmetrical
* asymmetrical

----
echo "Cats are Amazing" > hiddenmessage.txt
gpg -c hiddenmessage.txt
cat hiddenmessage.txt.gpg

# this clears the cached password
echo RELOADAGENT | gpg-connect-agent

gpg -o output.txt hiddenmessage.txt.gpg

rm hiddenmessage.txt.gpg
rm output.txt

gpg --gen-key

gpg --armor --output pubkey.txt --export 'Adrian'
gpg --armor --output privkey.asc --export-secret-keys 'Adrian'

gpg --encrypt --recipient 'Adrian' hiddenmessage.txt
gpg --output decrypted.txt --decrypt hiddenmessage.txt.gpg
----

=== Architecture odds and ends

**Cost efficient** or **cost effective**: Implementing a solution within
AWS using products or product features that provide the required service
for as little initial and ongoing cost as possible.
Using your funds effectively and knowing if product X is better or worse
than product Y for a given solution.

**Secure**: In a systems architecture context, implementing a given
solution that secures data and operations as much as possible from
an internal or external attack.

**Application session state**: data that represents what a custome is
doing, what they have chosen, or what they have configured.
Examples include items and quantities in a shopping cart, notes on
an X-ray, and 3D position of a real-time heart scan. Session
state can be stored on a server (**stateful** server) or externally
to a server (**stateless** server).

**Undifferentiated heavy lifting**: A part of an application, system,
or platform that is not specific to your business. Allowing a vendor
(AWS) to handle this part frees your staff to work on adding direct value
to your customers.

== AWS Architecture 101

=== Accounts

AWS account has single root user.

Isolated blast radius.

Multi-account strategies.

By default only root user has rights to access
resources in the account.

Accounts can be linked and configured to allow
**consolidated billing** where a **master** account is charged for all
**member** account resource usage.

=== AWS Physical and Networking Layer

AWS Region
* data stored in specific country.

us-east-1 - US East (N. Virginia)
us-east-2

Most product operate in a region-isolated way.

Region contain availability zones (AZs), which are separated and
isolated networks. A failure in one AZ generaly **won't impact
another**.

AZs in the same region are connected with **redundant**, **high-speed**,
**low-latency** network connections.

Most AWS services run within AZs. Some services operate from one AZ,
while other s replicated between AZs. Some services allow you to chose
the AZ to use, and some don't.

**Edge locations** are small pockets of AWS compute, storage,
and network close to major populations and are generally used
for **edge computing** and **content delivery**.


=== AWS Well-Architected Framework

AWS Well-Architected Framework is a set of documents.

Pillars:

* Security
    ** Implement a strong identity foundation.
    ** Enable traceability.
    ** Apply security at all layers.
    ** Automate security best practices.
    ** Protect data in transit and at rest.
    ** Prepare for security events.
* Reliability
    ** Test recovery procedures.
    ** Automatically recover from failure.
    ** Scale horizontally to increase aggregate system availability.
    ** Stop guessing capacity.
    ** Manage change in automation.
* Performance Efficiency
    ** Democratize advanced technologies.
    ** Go global in minutes.
    ** Use serverless architectures.
    ** Experiment more often.
    ** Mechanical sympathy.
* Operational Excellence
    ** Perform operations as code.
    ** Annotate documentation.
    ** Make frequent, small, reversible changes.
    ** Refine operations procedures frequently.
    ** Anticipate failure.
    ** Learn form all operational failures.
* Cost Optimization
    ** Adopt a consumption model.
    ** Measure overall efficiency.
    ** Stop spending money on data center operations.
    ** Analyze and attribute expenditure.
    ** Use managed services to reduce cost of ownership.


== AWS Product Fundamentals

=== S3

S3 is a global service.

* Bucket name has to be unique globally across
  all regions and all accounts.
* Files are replicated across availability zones
  in the region.
* buckets have flat structure.
* object names are unique within a bucket
* file size up to 5TB
* By default, there's a limit of 100 buckets

=== CloudFormation

Formats: JSON, YAML

. Template - contains **logical** resources and configuration.
. Stack - created and modified basing on templates.
. Physical resources - stacks take **logical resources** from
  template and create, update, or delete the **physical resource**
  in AWS.

Template sections:

* AWSTemplateFormatVersion
* Description
* Metadata
* Parameters
* Mappings
* Conditions
* Transform
* Resources
* Outputs

Example:

[source]
----
{
  "Resources": {
     "catpics" : {
        "Type": "AWS::S3::Bucket"
     }
  }
}
----

Key points:

* CFN template is written in JSON or JAML
* a template can create up to 200 resources
* if a stack is deleted, then by default, any resources
  it has created are also deleted.
* a stack can be updated by uploading new version of a template.
* new logical resources cause new physical resources.
* removed logical resources cause the stack to delete the
  physical resources
* changed logical resources update with some disruption or replace
  physical resources.

== IAM (Identity and Access Control)

ARN - Amazon Resource Name

ARN always begin with:

 arn:partition:service:region:account-id:

* partition - *aws* or *aws-cn* (for China)
* service - the AWS service: *s3*, *ec2*, *rds*, *dynamobd*
* region - region-code: *us-east-1*, *ap-southeast-2*

Example arns:

 arn:aws:iam::123456789012:user/roffle
 arn:aws:s3:::myamazingcatpics/truffs.jpeg
 arn:aws:dynamodb:us-east-1:123456789012:table/ratemycats

Credentials:

* username and password
* access keys
* short term credentials - used by roles

By defalut IAM identity has no permissions.

=== IAM policies

Types:

* identity policy
* resource policy

Policy has no effect until it is  attached to something.

Policy document is a list of *statements*:

[source]
----
{
  "Version": "2019-10-17",
  "Statement": [
    {
      "Sid": "SpecificTable",
      "Effect": "Allow",
      "Action": [
        "dynamodb:BatchGet",
        "dynamodb:DescribeStream",
        "dynamodb:DescribeTable",
        "dynamodb:Get*",
        "dynamodb:Query",
        "dynamodb:Scan",
        "dynamodb:BatchWrite*",
        "dynamodb:CreateTable",
        "dynamodb:Delete*",
        "dynamodb:Update*",
        "dynamodb:PutItem"
      ],
      "Resource": "arn:aws:dynamodb:*:*:table/CatPics"
    }
  ]
}
----

When there is no explicit permision, than there's implicit default deny.

Explicit deny -> Explicit allow -> Implicit deny

Exam hints:

* hard limit of 5k IAM users per account.
* 10 group memberships per IAM user
* default maximum of 10 managed policies per user
* no inline limit, but you cannot exceed 2048 characters for all
  inline policies on an IAM user.
* 1 MFA per user
* 2 access keys per user

=== Groups

* Groups are admin feature to group IAM users.
* Groups can contain many IAM users, and users can be in many groups.
* Groups are not **true** identities, they cannot be referenced
  from resource policies.
* Groups have no credentials.

=== Access keys

Access key consist of:

* Access Key ID
* Secret Access Key

Max 2 access keys per user.

You cannot authenticate to management console
with access keys.

In My Account activate:
"IAM User and Role Access to Billing Information"
to be able to give users access to billing information.

=== AWS CLI

 $ aws configure

To configure access keys.

 $ aws configure --profile test-user
 $ export AWS_PROFILE=test-user

=== Roles

Roles are *assumed* by another identity allowed
in the *trust policy*:

* IAM user
* AWS service
* another AWS account
* web identity
* anonymous identity

When role is assumed, the Security Token Service
(*STS*) generates a **time-limited** set of access
keys (temporary security credentials).

These access keys have the permissions defined in the permission policy.
IAM roles have no long-term credentials (access keys
or username and password).

Every role has two policies:

* trust policy - controls who can assume the role
* permission policy - policy that gives the role permission on things

Paterns:

* to gain additional permissions only when you need it
* service accesss
* for granting permissions to users from another AWS account
* multiple AWS accounts in the company - single IAM account

== Multi-Account Management and Ogranizations

**AWS Organizations** is a service for managing
**multiple accounts** within a single business.

All accounts within an AWS Organization can
**consolidate bills** into a single account.

Organizations can share bulk discounts and manage
accounts and permissions and limit account usage using **service control policies**.

* master account
* member accounts

Base limit is 2 accounts within an organization.

FullAWSAccess - service control policy allowing access to
all AWS services within an attached member account.

== EC2 Fundamentals

Instance Store Volume is not persisted in case of failure.

Security Group - protocol, port

CloudWatch - 5 min granularity.
Can enable 1 min granularity with **Detailed Monitoring**,
but associated with extra cost.

Instance states:

* running
* stopped
* pending
* stoping

Billed by the second with the minimum of 50 seconds.

=== Instance types

Instance families:

* general purpose
* compute optimized
* memory optimized
* accelerated computing
* storage optimized

Instance types:

* **T2**, **T3** - low-cost with burst capability
* **M5** - for general workloads
* **C5** - cpu
* **X1**, **R4** - memory
* **I3** - fast IO
* **P2**, **G3**, **F1** - GPU and FPGA

Instance sizes:

* nano
* micro
* small
* medium
* large
* x.large
* and larger 2xlarge, 4xlarge...

Special cases:

* a - AMD CPU
* A - Arm based
* n - higher speed networking
* d - NVMe storage

=== Storage

SAN or NAS - block storage

EBS (Elastic Block Storage) is a storage service that
**creates and manages volumes**.

Volumes are:

* persistent
* can be attached and removed to EC2 instances
* are replicated within a single AZ

**Instance store volumes**:
* are attached to EC2 host.
* Known as **ephemeral devices**.
* Best storage perforamnce
* when the host fails, the storage is lost
* should be regarded as temporary
* example: storage optimized instance types

Attaching storage:

----
$ lsblk
$ sudo mkdir /ephemeral
$ sudo mkfs -t ext4 /dev/nvme1n1
$ sudo mount /dev/nvme1n1 /ephemeral
----

When doing instance-level reboot emphemeral storage
is maintained.

After stopping and starting ephemeral storage is lost.

Volume types:

* **standard** - magnetic
* **sc1** - Cold HDD - lowest cost, infrequent access, can't be boot volume.
* **st1** - Throughput Optimized - low cost, throughput intensive, can't be a boot volume.
* **gp2** - general purpose SSD - default, balance of IOPS/MiB/s - burst pool IOPS per GB
* **io1** - Provisioned IOPS - highest performance, can adjust size and IOPS separately


To protect against AZ failure, EBS snapshots (to S3)
can be used.
Data is replicated across AZs in the region and
(optionally) internationally.

IOPS - number of input and output operations that storage can
perform in a given second.

Throughput - data rate.

gp2:

* you get 3 IOPS per every GB of volume size
* burst up to 3k IOPS
* minimum 100 IOPS
* max 16k IOPS
* burst pull - you get 5.4 million starting credits

io1:

* size and IOPS set separately
* max 64k IOPS for volumes
* max throughptu per volume 1k MiB/s

Facts:

* EBS supports a maximum per-instance throughput of 1,750 MiB/s
  and 80k IOPS.

=== Snapshots

Inconsistent snapshot - when the instance is runnig.

Options for conistent snapshot:

* flush any in-memory caches to disk
* stop instance for root volume snapshots

Sharing snapshots:

* by default snapshot is private
* you can share snapshot with specific AWS accounts
* You can enable public access
* you can copy the snapshot to another region

Data Lifecycle Manager:

* shedule and manage the creation and deletion of EBS snapshots

Snapshots are stored in S3.

Snapshots are stored incrementally.

=== Security groups

Every instance is created with its default ENI
(Elastic Network Interface).

Security groups are  software firewalls that can be attached to network interfaces
and (by association) products in AWS.

Security groups each have inbound rules and outbound rules.

A rule allows traffic to or from a source (IP, network,
named AWS entity) and protocol.

Security groups have a hidden implicit/default deny rule, but
**cannot explicitly deny traffic**.

Security groups are stateful - any traffic allowed in/out,
the return traffic is automatically allowed.

Security groups can reference:

* AWS resources
* other security groups
* themselves

Max 5 security groups for every ENI.

Security group belongs to VPC.

=== Instance metadata

http://169.254.169.254/latest/meta-data
http://169.254.169.254/latest/meta-data/ami-id
http://169.254.169.254/latest/meta-data/instance-id
http://169.254.169.254/latest/meta-data/instance-type

=== AMI

Amazon Machine Image

They store:

* snapshots of EBS volumes
* permissions
* block device mapping

AMIs can be shared, free, or paid and can be copied
to other AWS regions.

Types of AMIs:

* Instance store backed AMIs
* EBS backed AMIs

Snapshots are created when creating AMI.

AMI permissions:

* defaults to private
* can be public
* can be shared with specific AWS accounts

Bootstrapping:

* user data script
* cloud-init config

=== EC2 Networking Fundamentals

* public instance - with public IP
* private instance - only can be communicated inside the VPC

Private IP addresses don't change when instance
is stopped.

Public ip doesn't change at restart.

Public ip changes when instance is stopped and started.

=== EC2 Instance roles

EC2 **instance roles** are IAM roles that can be assumed by EC2 using an
intermediary called an **instance profile**.

An instance profile:

* is either created automatically when using the console UI
  or manually when using the CLI.
* is a container for the role that is associated with an EC2 instance.
* allows applications on the EC2 instance to access the credentials
  the role using the **instance metadata**.

Credential order:

. Command line options:
+
 $ aws [commond] --profile [profile-name]
+
. Environment variables: AWS_ACCESS_KEY_ID,
  AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN.
+
Recommended for temporary use in non-production
environments.
+
. AWS CLI credentials file
+
  $ aws configure
+
. container credentials
+
IAM Roles associated with AWS Elastic Container Service (ECS)
Task Definitions.
Temporary credentials are available to the Task's containers.
This is **recommended** for ECS environments.
+
. Instance Profile Credentials
+
IAM Roles associated with EC2 instances via
Instance Profiles.
This is recommended for EC2 environments.

=== Lab

==== To create role

Create file _trust_policy_ec2.json_

[source,json]
----
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {"Service": "ec2.amazonaws.com"},
      "Action": "sts:AssumeRole"
    }
  ]
}
----

To create role:

 $ aws iam create-role --role-name DEV_ROLE --assume-role-policy-document file://trust_policy_ec2.json

==== Create managed policy

Create file _dev_s3_read_access.json_

[source,json]
----
{
    "Version": "2012-10-17",
    "Statement": [
        {
          "Sid": "AllowUserToSeeBucketListInTheConsole",
          "Action": ["s3:ListAllMyBuckets", "s3:GetBucketLocation"],
          "Effect": "Allow",
          "Resource": ["arn:aws:s3:::*"]
        },
        {
            "Effect": "Allow",
            "Action": [
                "s3:Get*",
                "s3:List*"
            ],
            "Resource": [
                "arn:aws:s3:::<DEV_S3_BUCKET_NAME>/*",
                "arn:aws:s3:::<DEV_S3_BUCKET_NAME>"
            ]
        }
    ]
}
----

 $ aws iam create-policy --policy-name DevS3ReadAccess --policy-document file://dev_s3_read_access.json

==== Attach policy to role

 $ aws iam attach-role-policy --role-name <role-name> --policy-arn <policy-arn>

 $ aws iam list-attached-role-policies --role-name <role-name>

 $ aws iam get-policy --policy-arn <policy-arn>

 $ aws iam get-policy-version --policy-arn <policy-arn> --version-id <policy-version>

==== Create instance profile

 $ aws iam create-instance-profile --instance-profile-name DEV_PROFILE

 $ aws iam add-role-to-instance-profile --instance-profile-name <profile-name> --role-name <role-name>

 $ aws iam get-instance-profile --instance-profile-name <profile-name>

==== Attach instance profile to EC2 instance

----
$ aws ec2 associate-iam-instance-profile --instance-id i-03d70110f4b012e08 --iam-instance-profile Name=DEV_PROFILE

{
    "IamInstanceProfileAssociation": {
        "InstanceId": "i-03d70110f4b012e08",
        "State": "associating",
        "AssociationId": "iip-assoc-06a940e64e14b97e8",
        "IamInstanceProfile": {
            "Id": "AIPA367XEJHYAYVDRPIIN",
            "Arn": "arn:aws:iam::822467643888:instance-profile/DEV_PROFILE"
        }
    }
}
----

 $ aws describe-instances --instance-ids <instance-id>

==== Verifying role association

SSH into target host.

----
$ aws sts get-caller-identity

{
    "Account": "822467643888",
    "UserId": "AROA367XEJHYJ6MOLSVSB:i-03d70110f4b012e08",
    "Arn": "arn:aws:sts::822467643888:assumed-role/DEV_ROLE/i-03d70110f4b012e08"
}
----

=== Lab - tagging

* Tag Editor: https://docs.aws.amazon.com/ARG/latest/userguide/tag-editor.html
* Tagging Strategies: https://aws.amazon.com/answers/account-management/aws-tagging-strategies/
* Tagging and Cost Allocation: https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html#allocation-what
* AWS Resource Groups: https://docs.aws.amazon.com/ARG/latest/userguide/welcome.html
* AWS Systems Manager: https://docs.aws.amazon.com/systems-manager/latest/userguide/what-is-systems-manager.html
* AWS Config: https://docs.aws.amazon.com/config/latest/developerguide/WhatIsConfig.html

Tagging categories:

. Technical tags
  .. Name
  .. ApplicationId
  .. ApplicationRole
  .. Cluster
  .. Environment
  .. Version
. Tags for Automation:
  .. Date/Time
  .. Opt in/Opt out - used to indicate whether a resource
     should be automatically included in an automated activity,
     such as starting, stopping, or resizing instances.
  .. Security
. Business Tags
  .. Owner
  .. Cost Center/Business Unit
  .. Customer
  .. Project
. Security Tags
  .. Confidentiality
  .. Compliance

== Advanced

=== Volume encryption

Volume encryption uses EC2 host hardware to encrypt data **at rest** and
**in transit** between EBS and EC2 instances.

Encryption generates a data encryption key (**DEK**) from a customer
maste key (**CMK**) in each region.

A unique DEK encrypts each volume.

Snapshots of that volume are encrypted with the **same DEK**, as are any volumes
created from that snapshot.

KMS manages DEKs.

KMS - Key Management Service

KMS is regional service.

Every key starting with "aws/" is AWS-managed customer master key (CMK).

You cannot create unencrypted snapshot from encrypted volume.

The snapshot will be encrypted with same data encryption key that was used
in the volume. Same for volumes created from the snapshot.

=== Networking

Traditionally, virtual networking meant an EC2 host arranging access
for _n_ virtual machines to access one physical card - this multitasking
is done in software and is typically slow.

**Enhanced networking** uses SR-IOV (Single Root IO Virtualization), which
allows a single physical metwork card to appear as multiple physical devices.
Each instance can be given one of these (fake) physical devices.
This results in **faster transfer rates**, **lower CPU usage**, and **lower
consistent latency**.

EC2 delivers this via the Elastic Network Adapter (ENA) or Intel
62599 Virtual Function (VF) interface.

=== Placement groups

**Cluster Placement Groups** place instances physically near each other in a single AZ.

Every instance can talk to every other instance at the same time at
full speed.

Works with enhanced networking for peak performance.

**Partition PGs** - instanced deployed into a Partinion PG (PPG) are separated
into partitions (max of seven per AZ), each occupying
isolated racks in AZs/regions.

PPG can span multiple AZs in a region.

PPGs minimize failure to a partition and give you visibility on placement.

**Spread PGs** (SPG) - purely for availability.

SPGs are designed for a max of seven instances per AZ that need to be
separated.

Each instance occupies a partition and has an isolated fault domain.

Gread for email servers, domain controllers, file servers, and application HA pairs.

=== Billing

**On demand** - per second with minimum 60 seconds.

**Spot instances** allow **conumption of spare AWS capacity** for a given instance type and size in a specific AZ.

Instances are provided as long as your bid price is above the spot price, and you only ever pay the spot price.

If your bid is exceeded, instances are terminated with a two-minute warning.

Spot fleets are a container for "capacity needs." You can specify pools
of instances of certain types/sizes aiming for a given "capacity".
A minimum percentage of on-demand can be set to ensure the fleet is always active.

Spot instances are perfect for non-critical workloads, burst workloads,
or consistent non-functional jobs that can tolerate interruptions
without impacting functionality.

Spot is **not suitable** for long-running workloads that require
stability and cannot tolerate interruptions.

**Reserved instances** lock in a reduced rate for **one** or **three**
years.

**Zonal** reserved instances include a **capacity** reservation.

**Regional** reservation doesn't have capacity reservation.

Your commitment incurs costs even if instances aren't launched.

Reserved purchases are used for long-running, understood, and consistent workloads.

Reserved instances payment options:

* No upfront
* Partial upfront
* All upfront

**Dedicated hosts** - physical hardware reservation.

You need to specify:

* instance type (eg. m5d.large)
* AZ
* Host recovery - when checked, EC2 instances on failed hosts will be transfered
  to new host, assuming you have one.

Reasons to use dedicated host:

* compliance and mandatory reasons.
* bring your own licence (BOYL)
* control instance placement

== Serverless achitecture

=== Event-driven architecture

When using event-driven architecture, a system
operates around "events" that represent **an
action or a change of state** - e.g. a button being clicked,
a file being uploaded, etc.

* much more efficient use of resources

Serverless architecture components:

* BAS - backend as a service - using third-party services where possible
  rather than runing your own. Examples: Auth0 or Cognito for
  authentication and Firebase or DynamoDB for data storage.
* FAS - function as a service - functions are only active (invoked)
  when they are needed (when event is received).

=== Lambda

Functions are code, which run in a runtime.

Functions are invoked by **events**, perform actions for up to **15 minutes**,
and terminate.

Functions are **stateless**.

Function assume role when running.

Event-based invocation (including time events).

Lambda function needs to to have unique name in the region in the account.

Minimum billed duration is 100 ms.

Memory: 128MB to 3008MB.

Timeout value - hard limit - max 15 minutes.

=== API Gateway

Pricing is based on the number of API calls, the data transfered and any caching
required to improve performance.

API Gateway can access some AWS services directly using proxy mode:

* EC2 (backed by EBS) - monolith
* Fargate (backed by Aurora) - microservice
* Lambda (backed by DynamoDB) - serverless

You can attach DynamoDB to API gateway.

API protocol:

* REST
* WebSocket

Endpoint type:

* Regional
* Edge optimized
* Private

You can enable CORS support on resource level.

To have API active you have to deploy it.

API can belong to muliple stages (prod, dev, test, v1, v2, etc.)

=== Step functions

Step Functions is a **serverless visual workflow service** that provides
**state machines**.

A state machine can orchestrate other AWS services with simple logic, branching,
and parallel execution, and it maintains a **state**.

Workflow steps are known as **states**, and they can perform work via **tasks**.

Step Functions allows for **long-running serverless workflows**.

A state machine can be defined using Amazon States Language (**ASL**).

Step Function runs for one year.

== Container-based compute and microservices

To install Docker on Amazon Linux 2:

 $ sudo amazon-linux-extras install docker
 $ sudo service docker start
 $ sudo chkconfig docker on
 $ sudo usermod -aG docker $USER

=== ECS - Elastic Container Service

Based on docker.

Modes:

Core components:

* Scheduling and Orchestration
* Cluster Manager
* Placement Engine

ECS cluster is a container of configuration.

EC2 based:

* EC2 Windows + Networking
* EC2 Linux + Networking

Fargate based - serverless approach:

* Networking only

Components: task definitions, tasks and services.

== Networking

OSI networking model:

1. physical (copper, fiber-optic, radio frequency)
2. data link (MAC addresses, frames)
3. network (ip addressing - addressing that can cross network boundaries)
4. transport (reliability)
5. session (response communication)
6. presentation (tls, conversion, encryption, compression and standards)
7. application (http, ssh, ftp)

Transport layer:

* TCP
  ** aimed for reliable transport
  ** uses *segments* to ensure data is received in the **correct order**
  ** adds **error checking**
  ** adds **ports** allowing different streams of communications to the same host
* UDP - aimed for speed

=== IP Addressing

32-bit value

x.x.x.x - four octects

Two parts: network and host.

Reserved IP addresses:

* 0.0.0.0 & 0.0.0.0/0 - all ip addresses
* 255.255.255.255 - breadcast address
* 127.0.0.1 - localhost (loopback) address
* 169.257.0.1 to 169.254.255.254 - a range of IP addresses which
  a device can auto configure with if its using DHCP and fails
  to automatically get an IP from a DHCP server.

IP address classes:

* A (/8) - 1.0.0.0 to 126.255.255.255 - 126 networks
* B (/16) - 128.0.0.0 to 191.255.255.255 - 16 382 networks
* C (/24) - 192.0.0.0 to 223.255.255.255 - 2 097 150 networks

Private address ranges:

* 10.0.0.0 to 10.255.255.255 - Class A
* 172.16.0.0 to 172.31.255.255 - Class B
* 192.168.0.0 to 192.168.255.255 - Class C

Private address ranges cannot be used directly over internet.

**CIDR** - Classless Inter-Domain Routing

=== Subnetting

Subnet cannot span across AZs.

=== IP routing

Scenario 1 - local:

* devices are on the same network
* Communication on layer 2 level
* networking stack does ARP (address resolution protocol)
* ARP request on local network for MAC address

Scenario 2 - separate subnets:

* on Layer 3 - it's single communication
* on Layer 2 - it's communication to/from router
* default gateway - an IP used to send data off the local network
* A to B communication:
** A generates L3 packet - the SRC is the IP-A, the DST is IP-B
** A knows its default gateway IP, so it uses ARP to find the Router MAC
** A passess the L3 packet to L2, wraps it in a L2 frame and
   sends this to the Router -MAC addresss
** Router receives this, strips away the L2 frame, checks the DST IP
** it konws the network of IP-B because it's connected to it
** R uses ARP to find the MAC of B, generates a frame to B, ptus the
   unaltered IP packet inside and sends to MAC-B
** B receives the frame, strips it away, and passes the packet to L3

Scenario 3 - over Internet

* communication over Internet uses BGP - Border Gateway Protocol
* BGP exchanges routes

==== Firewalls

Firewall establish a barrier between networks of different security levels
and historycally have been the first line of defence against
perimeter attacks.

What data a firewall can read and act on depends on the OSI Layer the firewall
operates at:
* Layer 3 (Network) - source/dest IP addresses or ranges
* Layer 4 (Transport) - Protocol (TCP/UDP) and port numbers
* Layer 5 (Session) - as layer 4, but understand response traffic
* Layer 7 (Application) - application specifics, e.g. HTML paths, images

==== Proxy server

* Handles outgoing traffic.
* can filter out content
* acts as a web cache

== VPC

Types:

* custom VPC
* default VPC

Default VPC:

* CIDR 172.31.0.0/16
* subnet created in every AZ - /20 subnet (4091 available addresses)
* default DHCP option set attached
* default SG - all from itself, all outbound
* default NACL - all inbound and outbound

Custom VPCs:

* CIDR min /16, max /28
* Tenancy: default or dedicated

Special addresses:

* .0 - network address
* .1 - router address
* .2 - DNS
* .3 - reserved for future use
* .X - breadcast address - last address in subnet

DHCP option sets:

* VPC can have only one DHCP option set associated with it

You can share subnet with other AWS account:

* you can share subnet within AWS organization
* other account can only deploy resources into subnet, it cannot modify its settings

==== Routing

Every VPC has a virtual routing device called the VPC router.

It has an interface in any VPC subnet known as the "subnet+1"
addresss - for 10.0.1.0/24 this would be 10.0.1.1.

The router is highly available, scalable, and controls data entering and
leaving VPC and its subnets.

Each VPC has a "main" route table, which is allocated to all subnets in the VPC by default. A subnet must
have one route table.

Additional "custom" route tables can be created and associated with subnets - but only
one route table per subnet.

A route table controls what the VPC courer does with traffic leaving a subnet.

An internet gateway is created and attached to a VPC (1:1). It can
route traffic for public IPs to and from the internet.

Poutes:

A Router is a collection of routes that are used when traffic from
when traffic from a subnet arrives at VPC

Every route table has a local route, which matches the CIDR of the VPC
and lets traffic be routed between subnets.

A route contains a destination and a target. Traffic
is forwarded to the target if its destination matches
the route destination.

If multiple routes apply, the most specific is chosen.

Targets can be IPs ar AWS networking gateways/objects.

A subnet is a public subnet if:

* subnet is configured do allocate public IPs (but it can be
  overriden when deploying instance to the subnet)
* the VPC has an associated Interent Gateway
* subnet has a default route to that internet gateway.

**Internet gateway**:

* needs to be attached manually to
  specific VPC after creation.
* can only be attached to one VPC
* VPC can have at most one internet gateway
* gateway does **static network address translation** (static NAT)

Route propagation:

VPG - can propagate any routes from the route table
  to VPG.

=== Bastion host

private dns: ip-x-x-x-x.ec2.internal
public dns: ec2-18-205-247-220.compute-1.amazonaws.com

=== NAT

Static NAT - a private IP is mapped to a public IP (what IGWs do)

Dynamic NAT - a range of private addresses are mapped
onto one or more public (used by your home router and NAT gateways).

AWS:

* NAT gateways
* NAT instances

NAT gateway

* must be placed in public subnet
* must have elastic IP assigned
* are not high available
* must be placed in a single subnet
* scale with load
* initially supports over 5Gb of bandwidth, can scale up to 45Gb

To have NAT instance working you have to disable **Source and destination check**

=== Network Access Control Lists (NACL)

NACL operate at Layer 4 of the OSI model (TCP/UDP) and below.

A subnet has to be associated with a NACL - either the VPC default
or custom NACL.

NACLs only impact craffic crossing the boundary of a subnet.

NACLs are collections of rules that can explicitly allow or deny
traffic based on its protocol, port range, and source/destination

Rules are processed in number order, lowes first. When a match is
found, that action is taken and processing stops.

The "*" rule is processed last and is an implicit **deny**.

NACLs have two sets of rules: inbound and outbound.

**Ephemeral ports**:

* when a client initiates communications with a server, it is to a well-known
  port number on that server
* the response is from that well-known port to an ephemeral port on the client.
  The client decides the port.
* NACLs are stateless, they have to consider **both** initiating and
  response traffic - tsate is a session-layer concept.

* practical range of ephemeral ports: 1024-65535

=== Creating VPC

. Create VPC
. Create subnets
. Set __Auto-assign public IPs__ for public subnets.
. Add Internet Gateway and assign it to the VPC.
. Create route table which routes to Internet Gateway
. Associate public subnets with public route table.

=== VPC Peering

Allows direct communication between VPCs.

Services can communicate using private IPs from VPC to VPC.

VPC peers can span AWS accounts and even regions (with some limitations).

Data is encrypted and transits via the AWS global backbone.

VPC peers are used to link two VPCs at layer 3: company mergers,
shared services, company and vendor, auditing.

Important limits and considerations:

* CIDR blocks cannot overlap
* VPC peers connect two network - routing is not transitive.
* routes are required at both sides (remote CIDR -> peer connection)
* NACLs and SGs can be used to control access
* SGs can be referenced but **not** cross-region.
* IPv6 support is not available cross-region.
* DNS resolution to private IPs can be enabled, but it's a setting
  needed at both sides.

VPC Peering are configured with a **Peering Connection**.

Steps:

. create peering connection
. configure routing - both sides
. configure NACLs (if necessary)
. configure Security Groups

You can enable private address resolution by editing dns settings on
peering connection:

* Requester DNS resolution
* Accepter DNS resolution

There is no transitive routing in peering connections.

=== VPC Endpoints

**VPC Endpoints** are gateway objects created within a VPC.
They can be used to connect to AWS public services without the need
for the VPC to have an attached internet gateway and be public.

VPC Endpoint types:

* gateway endpoints: can be used for DynamoDB and S3
* Interface endpoints: Can be used for everything else (e.g. SNS, SQS)

When to use VPC Endpoint:

* if the entire VPC is private with no IGW
* if a specific instance has no public IP/NATGW and needs to access public services.
* to access resources restricted to specific VPCs or endpoints (private S3 bucket)

Limitations and considerations:

* Gateway endpoints
  ** are used via route table entries - they are geateway devices.
     **Prefix lists** for a service are used in the destination field with the gateway
     as the target.
  ** gateway endpoints can be restricted via policies.
  ** gateway endpoints are HA across AZs in a region.
* Interface endpoints:
  ** are interfaces in a specific subnet.
     For HA, you need to add multiple interfaces - one per AZ.
  ** are controlled via SGs on that interface.
     NACLs also impact traffic.
  ** add or replace the DNS for the service - no route table updates are required.
  ** code changes to the endpoint DNS, or enable private DNS to override
     the default service DNS.

=== IPv6 within AWS

* not supported for every AWS product

* You have to enable IPv6 support for VPC - you get /56 IPv6 CIDR range.
* You have to edit IPv6 CIDRs for subnet to add IP range
* Modify route tables (IGW)
* Add entries to NACLs for IPv6

In IPv6 every address is publicly routable.

Limitations:

* DNS names are not allocated to IPv6 addresses.
* IPv6 addresses are all publicly routable - there is no concept of private vs public with IPv6.
* with IPv6 the OS is configured with this public address via DHCP6.
* Elastic IPs aren't relevant with IPv6.
* not currently supported for VPNs, customer gateways, and VPC endpoints.

=== Egress only IGW

**Egress-only internet gateways** provide IPv6 instances with outgoing access
to the public internet using IPv6 but prevent the instances from
being accessed **from** internet.

NAT isn't required with IPv6, and so NATGW's aren't compatible with
IPv6. Egress-only gateways provide the outgoing-only access of a NATGW
but do so without adjusting any IP addresses.

== DNS - Domain Name System

Resolver::
  Piece of software that resolves DNS addresses.

DNS Root Servers::
  a group of servers that are authoritative to give answers about the root zone.
  TLD (top level domains) are controlled by the root zone.

Top-Level Domain (TLD)::
  the top tier in the DNS hierarchy. Large orgs or country orgs are delegated
  control of these by the root servers to be authoritative.

Subdomain::
  anything between a host and a TLD is a subdomain.

Zone and Zone Files::
  a mapping of IPs and hosts for given subdomain.

Records::
  DNS has lots of record types - A, MX, AAAA, Cname, TXT, NS

Name Server::
  runs a DNS service and can either store or cache information for
  the DNS platform. Whether a name server caches or acts as an authority
  depends on if it's referenced from a higher level.

Authoritative::
  The root servers are authoritative for the root zone - they are
  used by every operating system and networking stack globally.
  The root servers delegate ownership of a part of the hierarchy, such
  as .com, to an organization. That organization runs name servers that become
  authoritative - they can answer queries with authority. Because the root points
  at these servers, they are authoritative.

Hosts::
  A record in a zone file.

FQDN::
  Fully qualified domain name.

=== Public vs private zones

Private zones:

* created manually
* associated with one or more VPCs
* private zones need **enableDdsHostnames** and **enableDnsSupport**
  enabled on a VPC
* not all Route 53 features supported - limits on health checks
* split-view DNS is supported, using the same zone name for
  public and private zones - providing VPC resources with different records
  (e.g. testing, internal versions of websites).
  ** vith split view, private is preferred - if no matches, public
     is used.

Record set types:

* A (and AAAA) - host to IP (AAAA maps to IPv6)
* CNAME - alias for subdomain or fully-qualified domain name.
  ** cant be sued for naked domain name
* MX - mail servers
  ** each MX record has a priority. Remote mail servers
     use this to locate the server to use when sending mail.
* NS record - used to set authoritative servers for a subdomain.
* TXT record - used for descriptive text in a domain - often
  used to verify domain ownership.
* Alias records - an extension of CNAME - can be used like an A record,
  with the functionality of a CNAME and none of the limitations.
  Can refer to AWS logical services (load balancers, S3 buckets), and
  AWS doesn't charge for queries of alias records against AWS resources.

=== Health checks

Settings:

* Check types:
  ** Endpoint
  ** Status of other health checks (calculated health check)
  ** State of CloudWatch alarm
* Request interval
* feature threshold
* string matching
* latency graph checkbox
* invert health check checkbox
* health check sources selection

=== Routing policies

==== Simple routing policy

* maps to ip
* can be multivalued.
* can map to alias: single S3 bucket, ELB, CloudFront distribution, etc.

==== Failover routing policy

You can create multiple records with the same name.

**Set ID** setting must be unique amongst all
records with the same name.

Types of records:

* primary
* secondary

You can only create one record of given type.

==== Weighted routing policy

Multiple records, each has a weight.

Weighted routing is not meant for load balancing.

==== Latency-based routing

Route 53 consults a latency database each time
a request occurs to a given latency-based host in DNS
from a resolver server.

Record sets with the same name are considered part of the same
latency-based set.

Each is allocated to a region.

The record set returned is the one with the lowest latency to the resolver server.

You need to specify the region for each record.

==== Geolocation routing

==== Multivalue answer

Route 53 responds to DNS queries with up to eight healthy records
selected at random.

Each record can have health check attached.

== S3

=== Permissions

Bucket authorization within S3 is controlled
using **identity policies** on AWS identities,
as well as **bucket policies** in the form of resource
policies on the bucket and bucket or object **ACLs**.

Priority order: Explicit Deny, Explicit Allow, Implicit Deny.

Initially only the account that created the bucket has permissions.

Identity policy example:

[source,json]
----
{
  "Version": "2019-10-17",
  "Statement": [
    {
      "Sid": "FirstStatement",
      "Effect": "Allow",
      "Action": "s3:ListAllMyBuckets",
      "Resource": "*"
    },
    {
      "Sid": "SecondStatement",
      "Effect": "Allow",
      "Action": [
        "s3:List*",
        "s3:Get*"
      ],
      "Resource": [
        "arn:aws:s3:::ac-catpics1337",
        "arn:aws:s3:::ac-catpics1337/*"
      ]
    }
  ]
}
----

By **identity policies** you can only grant to users, groups and role in **your** account.

**Resource policy** - **bucket policy** allows to grant permissions for
other accounts and anonymous users.

AWS recommend not to use **bucket ACLs**.

Block public access checkboxes.

=== Transferring data to S3

Methods:

* S3 console,
* aws cli
* directly using API

Single PUT upload - limit of 5GB, can cause performance issues when
the whole upload fails.

Multipart upload:

* recommended for anything greater than 100MB
* object is broken into parts (up to 10 000)
* each part is 5MB to 5GB, and the last part can be less (the remaining data).

=== Encryption

Data between a client and S3 is encrypted **in transit**.

Encryption **at rest** can be configured on a **per-object** bosis.

* **client-side encryption** - the client is responsible for managing
  both the encryption/decryption proces and its keys.
* **server-side encryption with customer-managed keys (SSE-C)** -
  handles the encryption and decryption process. The customer
  is still responsible for key management, and keys must be supplied
  with each PUT or GET request.
* **server-side encryption with S3-managed keys (SSE-S3)** -
  objects are encrypted using **AES-256** by S3. The keys are generated by S3
  (using KMS). Keys are stored with objects in an encrypted form. If you
  have permissions on the object, you can decrypt it and access it.
* **server-side encryption with AWS KMS-managed keys (SSE-KMS)** -
  objects are encrypted using individual keys generated by KMS.
  Encrypted keys are stored with the encrypted objects.
  Decryption of an object needs both S3 and KMS key premissions (role separation).

Object are encrypted in S3, not buckets.

Each PUT operation needs to specify encryption (and type) or not.

A bucket default captures any PUT operations whene no encryption method/directive is specified.

It doesn't enforce what type can and can't be used.

Bucket policies can enforce encryption.

==== Versioning

You can never disable versioning, once you have enabled it.
It can only be suspended.

==== Presigned URLs

A presigned URL can be created by an identity in AWS.

Provides access to an object using the creator's access permissions.

When the presigned url is used, AWS verifies the **creator's access** to the object.

The URL is encoded with authentication built in and has an expiry time.

Presigned URLs can be used to **download** or **upload** objects.

Common error situations:

* presigned URL has expired
* the permissions of the creator of the URL have changed
* the URL was created using a role (36-hour max)
  and the role's temporary credentials have expired
  (aim to never create presigned URLs using roles).

Presigning with aws cli:

 $ aws s3 presign s3://jc-test-3/index.html

==== Storage classes

Storage classes is also known as **storage tier**.

Storage classes influence the cost, durability, availability, and "first byte latency".

The class used for an object can be changed manually or using lifecycle policies.

**Standard class**:

* default, all-purpose storage
* 11-nines durability and 4-nines availability.
* replicated in 3+ AZs - no minimum object size or retrieval fee

**Standard Infrequent Access (Standard-IA)**:

* object where real-time access is required, but infrequent
* 99.9% availability, 3+ AZ replication, cheaper than Standard
* 30-day and 128KB minimum charges and object retrieval fee

**One Zone-IA**:

* non-critical and/or reproducible objects
* 99.5% availability, only 1 AZ, 30-day and 128KB minimum charges
* cheaper than Standard and Standard-IA

**Glacier**:

* long-term archival storage (warm or cold backups)
* retrievals could take minutes or hours (faster = higher cost)
* 3+ AZ replication, 90-day and 40KB minimum charge and retrieval

**Glacier Deep Archive**:

* long-term archival (cold backups) - 180-day and 40KB minimums
* longer retrievals but cheaper than Glacier - replacement for tape-style storage

**Intelligent tiering**

* designed for unknowns access patterns
* after 30 days moves to standard-IA, when accessed, moved back to Standard
* you pay automation and monitoring cost


==== Lifecycle rules

* when object becomes previous version,
  ** specify days
  ** specify target storage class

* specify days after creation and target storage class.

Expiring objects:

* permanently delete previous versions after x days
  after becoming a previous version.

==== Cross-region replication

Allows one-way replication of data from a source bucket
to a destination bucket in another region.

By default, replicated objects keep their:

* storage class
* object name
* owner
* object permissions

Replication configuration is applied to source bucket,
and to do so requires versioning to be enabled on both buckets.

Replication requires an IAM role with permissions to replicate objects.

With the replication configuration, it is possible to override the storage class
and object permissions as they are written to the destination.

Excluded from replication:

* system actions (lifecycle events)
* any existing objects from before replication is enabled
* SSE-C encrypted objects  only SSE-S3 and (if enabled)
  KMS encrypded objects are supperted.

== CloudFront

Content Delivery Network.

CloudFront components:

* origin - the server or service that hosts your content.
  Can be S3 bucket, web server, or Amazon MediaStore.
* Distribution - the "configuration" entitiy within
  CloudFront. It's where you configure all aspects of a
  specific "implementation" of CloudFront from.
* Edge location - the local infrastructure that hosts
  caches of your data. POsitioned in over 150 locations
  globally in over 30 countries.
* Regional Edge Caches - larger versions of edge locations.
  Less of them but have more capacity and can serve larger areas.

Caching Process:

* create a distribution and point at one or more regions.
  A distribution has a DNS address that is used to access it.
* the DNS address directs clients at the closest available
  edge location.
* if the edge location has a cached copy of your data,
  it's delivered locally from the from that edge location.
* If it's not cached, the edge location attempts to download
  it from either a regional cache or from the origin (known as the
  origin fetch).
* as the edge location receves the data, it immediately begins
  forwarding it and caches it for the next visitor.

Content can:

* expire
* be discarded
* be recached
* you can explicitly invalidate content to remove it from caches

Delivery method:

* web
* RTMP - for Adobe Flash Media Server

Origins must be publicly accessible.

Restrict viever access
(use signed URLs or signed cookies) - private cloudfront distribution:

* Trusted signers: self or specified accounts

By default, CloudFront is publicly accessible.

A distribution can be configured to be **private** where each access
requires a signed URL or cookie. This is done by setting **trusted signers**
on the distribution.

Private distributions can be bypassed by going straight to the origin (e.g. an S3 bucket).

An orgin access identity (**OAI**) is a virtual identity that can be associated
with a distribution. An S3 bucket can then be restricted to only allow this
OAI to access it - all other identities can be denied.

1. Create origin access identity in cloudfront
2. Edit distribution origin to restrict bucket access and choose OAI
3. Edit bucket policy:
+
[source,json]
----
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "2",
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::cloudfront:user/CloudFront Origin Access Identity E32CA9HFEOB1NT"
            },
            "Action": "s3:GetObject",
            "Resource": "arn:aws:s3:::<bucket-name>/*"
        }
    ]
}
----

=== Network file systems

Amazon EFS - Elastic File System - implementation of NFS v4.

EFS is tied to a specific VPC.

Two performance modes:

* General Purpose
* Max I/O

Throughput mode:

* bursting - 100MiB/s of base burst, 100 MiB/s per 1TiB size.
  Earning 50 MiB/s per TiB of storage.
* provisioned

Only supported on linux.

Filesystems are accessible from a VPC or from on-premises locations via
a VPN or Direct Connect.

Security groups are used to control access to NFS mount targets.

EFS supports two storage classes:

* Standard
* Infrequent Access (IA)

Lifecycle management is used to move files between classes based on access patterns.

Allows encryption.

Installing on the instance:

 $ sudo yum install -y amazon-efs-utils
 $ sudo mkdir -p /mnt/efs
 $ sudo mount -t efs <filesystem-id>:/ /mnt/efs

Uses multiple AZs

== Databases

Two main db categories:

* sql
* non-sql

Non-sql databases:

* key-value - data stored as key and value pairs.
  Super-fast queries and ability to scale.
  No relationships and weak schema - Amazon DynamoDB
* document - data stored as structured key-value pairs
  called documents.
  Operation on documents are highly performant - MongoDB
* column - data is stored in columns rather than rows.
  Queries against attribute sets, such as all DOBs or all
  surnames are fast. Great for data warehousing and analytics - Amazon Redshift
* graph - designed for dynamic relationships.
  Stores data as nodes and relationships between these nodes.
  Ideal for human-related data, such as social media - neo4j

=== RDS

Database types:

* Aurora
* MySQL
* MariaDB
* PostgreSQL
* Oracle
* Microsoft SQL Server

RDS can be deployed in single AZ or Multi-AZ mode (for resilience).

RDS supports following instance types:

* general purpose (DB.M4 and DB.M5)
* memory optimiezed (DB.R4 and DB.R5, and DB.X1e and DB.X1 for Oracle))
* burstable (DB.T2 and DBT3)

Two types of storage:

* General Purpose SSD (gp2): 3 IOPS per GiB, burst to 3k IOPS
* Provisioned IOPS SSD (io1): 1k to 80k IOPS (engine dependent) size,
  and IOPS can be configured independently

RDS instances are charged based on:

* instance size
* provisioned storage
* IOPS if using io1
* data transferred **out**
* any backups/snapshots beyond the 100% that is free with each db instance

RDS supports encryption with following conditions:

* encryption can be configured when creating db instances
* encryption can be added by taking a snapshot, making encrypted snapshot,
  and creating new encrypted instance from that encrypted snapshot.
* encryption cannot be removed
* read replicas need to be the same state as the primary instance (encrypted or not)
* encrypted snapshots can be copied between regions - but a new destination region
  KMS CMK is used (because they are region specific)

Network access to RDS instance is controlled by a **security group**
associated with the RDS instance.

Creating database:

1. create database subnet group
2. create database

Storage autoscaling.

Standby instance.

Every database has an endpoint (CNAME), e.g.: rdslesson.cng9aqcehd6j.us-east-1.rds.amazonaws.com

For long term needs purchase RDS reserved instance.

Creating LAMP stack:

[source,bash]
----
sudo yum update -y
sudo amazon-linux-extras install -y lamp-mariadb10.2-php7.2 php7.2
sudo yum install -y httpd
sudo systemctl start httpd
sudo systemctl enable httpd
wget https://wordpress.org/latest.tar.gz
tar -xzf latest.tar.gz
sudo cp -r wordpress/* /var/www/html/
cd /var/www/html/
sudo cp wp-config-sample.php wp-config.php
sudo nano wordpress/wp-config.php

sudo chown -R apache /var/www
sudo chgrp -R apache /var/www
sudo chmod 2775 /var/www
sudo find /var/www -type d -exec sudo chmod 2775 {} \;
sudo find /var/www -type f -exec sudo chmod 0664 {} \;
sudo systemctl restart httpd
----

==== Backups

Automated backups to S3 occur daily:

* can be retained from 0 to 35 days (with 0 being disabled).
* backups are taken from the standby instance.

Manual snapshots are taken manually and exist until deleted,
and point-in-time log-based backups are also stored ond S3.

Log backups occur to S3 every 5 minutes, allowing point-in-time recovery
at any point in the backup retention window.

Restores create a new RDS instance with a new endpoint address - this
will require application changes.

==== Multi-AZ

RDS can be provisioned in single or multi-AZ mode

Multi-AZ mode provisions a primary instance and a standby instance in a different AZ
of the same region.

Only the primary can be accessed using the instance CNAME.

There is no preference benefit, but it provides a better RTO than restoring
a snapshot.

Replication to stanby instance is synchronous.

In case of primary failure, db CNAME gets changed to stanby instance.

You don't have any any access to standby instance.

You can have only one standby instance.


==== Read replicas

Read-only copies of an RDS instance.

Can be created in the same or different region from the primary instance.

Read Replicas can be addressed independently (each having their own dns).

Can be used for read workloads, allowing you to scale reads.

Five Read Replicas can be created from a RDS instance.

Read Replicas can be created from Read Replicas.

Read Replicas can be promoted to primary instances and can be themselves Multi-AZ.

Replication is **asynchronous**.

Reads from a Read Replica are eventually consistent.

To be able to create a Read Replica, you must turn on automatic backup on source database.

==== Aurora

Compatibile with MySQL and PostgreSQL.

* uses a database configuration of a "cluster"
* a cluster contains a single primary instance and zero or more replicas

Cluster storage:

* all instances (primary and replicas) use the same shared storage - the cluster
  volumes.
* cluster volume is totally SSD based, which can scale to 64TiB in size
* replicates data six times, across three AZs
* can tolerate two failures without writes being impacted and three failures without
  impacting reads.
* Aurora storage is auto-healing.

Cluster Scaling and Availaibility:

* cluster volumes scale automatically, only bills for **consumed data**,
  and is constantly backed up to S3
* Aurora replicas improve availability, can be promoted to be a primary instance
  quickly, and allow for efficient read scaling.
* reads and writes use the **cluster endpoint**
* reads use the **reader endpoint**, which palances connections over all
  replica instances.

Aurora can have up to 15 replicas.

To improve resilience, use additional replicas.

To scale **write** workloads, scale **up** the instance size.

To scale **reads**, scale **out** (adding more replicas).

Writer instance and reader instance.

Failover - tier-0 to tier-15.

Backtracking:

* max window of 72 hours
* You will get outage when backtracking.

Parallel query::
  allows queries to be executed against all nodes
  in the aurora cluster in the same time.

Aurora global database:

* one primary region - master of the data
* one read-only secondary region

You can use auto-scaling to dynamicly change number of reader instances.

==== Aurora serverless

Based on the same database engine as Aurora, but instead of provisioning certain resource
allocation, Aurora Serverless handles this as a service.

You simply specify a minimum and maximum number of **Aurora capacity units** (**ACUs**) -
Aurora Serverless can use the **Data API**.

Proxy Fleet - transparet set of proxy instances that directs traffic to aurora serverless instances, without
client application knowing any difference.

Removes much complexity of managing aurora db.

Aurora serverless exists in a singel AZ.

Instances are not hosted inside your VPC, you have no physical instances.

It uses service known as **private link**, which places endpoints inside a VPC to access remote services.

You can't currently acces an aurora serverless cluster from cross-vpn or inter-region vpc peer.

**Data API** allows to access database using traditional APIs.

==== DynamoDB

DynamoDB is a global service, partitioned regionally and allows the creation
of tables.

Described as key-value store or more appropriately as wide-column store.

* TABLE - collection of items that share the same partition key or partition key
  and sort key (sk) together with other configuration and performance settings.
* ITEM - a collection of attributes (up to **400kB** in size) inside
  a table that shares **the same key structure** as every other item in the table.
* ATTRIBUTE - key and value

The primary key is made up of a partition key (hash key)
and an optional sort key.

The partition key is used to partition data across hosts
for scalability and availability.

Choose an attribute which has a wide range of values
and is likely to have evenly distributed access patterns.

For example CustomerId is good while GameId is bad
if most of your traffic relates to a few popular games.

Partition key types: string, binary, number

Column data types:

* String
* Binary
* Number
* StringSet
* BinarySet
* NumberSet
* Map
* List
* Boolean
* null

Size limit for item 4000kB (primary, sort keys and names and values of attributes).

You cannot PUT or GET partial items.

You can apply resource-level permissions.

DynamoDB stores at least 3 replicas of the data.

Three replicas of the data.

DynamoDB will survive an AZ failure without any additional configuration.

Operations:

* scan - scans all items
* query - can only ever retrieve data for specified partition key.

Point-in-time recovery - you need to enable it to be able to restore table up to last 35 days.

Manual table backups:

* you can restore only to new table

Encryption:

* always enabled
* DEFAULT - server side encryption using AWS owned CMK
* KMS - server side encryption using AWS managed CMK

Global tables:

* table that replicate data to replica tables in other regions
* you have to enable streams for the table
* add replica tables
* multimaster replication - you can write to all replicas
* last writer wins
* table has to be empty when you enable global tables

Two read/write capacity models:

* provisioned throughput (default) - each table is configured with read
  capacity units (**RCU**) and write capacity units (**WCU**)
* on-demand - DynamoDB automatically scales to handle performance demands
  and bills a per-request charge

Each operation on ITEMS consumes at least 1 RCU or WCU - partial RCU/WCU cannot
be consumed.

Read Capacity Units:

* One RCU is 4kB of data read from a table per second in a strongly consistent way.
    ** Reading 2kB of data consumes 1 RCU.
    ** Reading 4.5kB takes 2 RCU
    ** reading 10 * 400 bytes takes 10 RCU.
* eventually consistent reads - 1 RCU per 2 x 4kB data reads per second.
* atomic transactions require 2x the RCU

Write Capacity Units:

* one WCU is 1kB of data or less written to a table
    ** an operation that writes 200 bytes consumes 1 WCU
    ** an operation that writes 2kB consumes 2 WCU
    ** five operations of 200 bytes take 5 WCU
* atomic transactions require 2x the WCU

When allocating performance:

* you allocate it to partitions, not to tables
* partition is replicated into three different AZs
* for each partition: single leader node and two non-leader nodes

Streams:

* rolling 24h window of changes
* provide an ordered list of changes that occur to items within a DynamoDb table.
* streams are enabled **per table** and only contain the data from
  the point of being enabled
* every stream has an ARN that identifies it globally across all tables,
  accounts, and regions.
* four view types:
  ** KEYS_ONLY: whenever an item is added, updated, or deleted, the key(s) of that
     item are added to the stream.
  ** NEW_IMAGE: the entire item is added to the stream "post-change"
  ** OLD_IMAGE: the entire item is added to the stream "pre-change"
  ** NEW_AND_OLD_IMAGES: both the new and old versions of the item are added
     to the stream

Triggers:

* streams can be integrated with AWS Lambda, invoking a function whenever
  items are changed in a DynamoBD table (a DB trigger)

Form of indexes:

* local secondary indexes (LSI)
  ** must be created during table creation
  ** use the same partition key, but an alternate sort key
  ** share the RCU and WCU values for main table
  ** max 5 LSI per table
* global secondary indexes (GSI)
  ** max 20 GSI per table by default, can be increased by support ticket
  ** can be created at any point after the table is created
  ** can use different partition and sort keys
  ** have their own RCU and WCU values
  ** data from the source table is replicated asynchronously
  ** you can't perform strongly consistent reads on global secondary index

Indexes are alternate representation of data in existing table.

Projected attributes: all, keys only, include selected fields.

==== DAX

DynamoDB Accelerator (DAX):
* is an in-memory cache designed specifically for DynamoDB.
* runs inside a VPC
* app uses DAX Client
* should not be used for consistent reads - every read from DAX is eventually consistent

Results devileverd from DAX are available in microseconds rather than
in single-digit milliseconds available from DynamoDB.

DAX maintains two distinct caches:

* the item cache
  ** populated with results from GetItem and BatchGetItem
  ** 5 minute default TTL
* the query cache
  ** populated with results from Query and Scan
  ** caches based on the parameters specified

==== ElastiCache

* managed in-memory data store
* supports the Redis or Memchached
* used for:
  ** offloading database reads by caching responses, improving
     app speed and reducing costs
  ** storing user session state, allowing for stateless compute instances

== Load balancing

Types of Elastic Load Balancers:

* Classic (CLB)
* Application (ELB)
* Network (NLB)

ELBs can be paired with Auto Scaling groups to enhance HA and fault tolerance.

A node is placed in each AZ the load balancer is active in. Each node gets 1/N of the traffic,
where N is the number of nodes. Historically, each node could only load balance to
instances in the same AZ. This results in uneven traffic distribution.
Cross-zone load balancing allows each node to distribute traffic to all instances.

An ELB can be public facing or internal.

=== Classic Load Balancers

* AWS recommends not to use CLB
* support layer 3 & 4 (TCP and SSL) and some HTTP/S features
* it isn't a Layer 7 device, so no real HTTP/S
* one SSL cert per CLB - can get expensive for complex projects
* can offload SSL connections - HTTPS to the load balancer and HTTP to
  the instance
* can be associated with Auto Scaling groups
* DNS A Record is used to connect to the CLB

=== Application load balancers (ALBs)

Operate at Layer 7.

Understand HTTP and HTTPS and can load balance based on this protocol layer.

ALBs are now recommended as the default LB for VPCs.

They perform better than CLBs and are almost always cheaper.

Content rules can direct certain traffic to specific target groups.

* host-based rules: route traffic based on the host used
* path-based rules: route traffic based on URL path

ALBs support EC2, ECS, EKS, Lambda, HTTPS, HTTP/2 and WebSockets.

ALBs can be integrated with AWS Web Application Firewall (WAF)

Use an ALB if you need to use containers or microservices.

Targets -> Target Groups -> Content rules

An ALB can host multiple SSL certificates using SNI.

* you can choose only one subnet per AZ

Supported listeners: http and https.

**Target groups**:

Target types:

* ec2 instance
* IP
* Lambda function

Listener rules:

* conditions:
  ** path
  ** http header
  ** http request method
  ** query string
  ** source ip

=== Network load balancers

Operate at Layer 4.

* can support protocols other than HTTP/S because it forwards upper layers unchanged
* Less latency because no processing above Layer 4 is required
* IP addressable - static address
* best load balancing performance within AWS
* source IP address preservation - packets unchanged
* targets can be addressed using IP address
* supports targets outside VPC
* routing requests to multiple applications on a single ec2 instance

== Scaling

Auto-scaling groups are based on:

* launch configurations
* launch templates

Launch configurations:

* AMI
* instance type
* key pair
* IAM role
* user data
* purchase options
* network configuration
* security groups

Launch templates:

* versioning and inheritance
* tagging
* more advanced purchasing options
* new instance features, including:
  ** elastic graphics
  ** T2/T3 unlimited settings
  ** placement groups
  ** capacity reservation
  ** tenancy options

You cannot change settings of existing launch configuration.

Scaling can be:

* manual
* scheduled
* dynamic

Scaling policies:

* simple
* step scaling
* target tracking

Default cooldown - min time between scaling events.

Scheduled actions.

To associate load balancer:

* classic load balancer - direct selection
* application load balancer - through target groups
* health check type: ec2 (default), ELB

== Hybrid and scaling

=== VPN

VPC VPN components:

* VPC
* Virtual Private Gateway (VGW) attached to a VPC
* a Customer Gateway (CGW) - configuration for on-premises router.
  Represents physical piece of hardware at client side
* VPN Connection (using 1 or 2 IPsec tunnels)

Dynamic Customer Gateway:

* dynamically exchange subnet information over BGP
* you need to provide BGP ASN (Autonomous System Number) - unique identifier for a BGP router.
* if you don't have existing ASN you can use a private ASN in the 64512-65534 range.

Best Practice & HA:

* use dynamic VPNs (uses BGP) where possible
* connect both Tunnels to your CGW - VPC VPN is HA by design
* where possible use two VPN connections and two CGWs

You download configuration for VPN connection, configuration contains information
needed to configure on-premise router.

You enable route propagation on route to VPG.

VPG versus Direct Connect:

* VPN are setup in minutes, Direct Connect potentially weeks or months
* VPN are cheaper for all but the highest load
* VPN have per-hour cost per active VPN connection and data charges
* performance of VPN is limited by a customer gateway equipment

Setups:

. single CGW and single tunnel
. HA AWS end - two tunnels
. Full HA - two CGWs and two tunnels at each of CGWs

Routing:

. local route always takes priority
. longest prefix
. static routes
. direct connect is preferred over VPN
  .. direct connect BGP
  .. static VPN
  .. BGP VPN

=== Direct connect

DX - Direct Connect - physical connection between your network and AWS either
directly via a cross-connect and customer router at a DX location
or via a DX partner provider.

**Dedicated Connections** are direct via AWS and use single-mode fiber,
running either **1 Gbps** using 1000Base-LX or **10Gbps** using 10GBASE-LR.

Virtual interfaces (VIFs) run on top of a DX.

Public VIFs can access AWS public services such as S3.

Private VIFs are used to connect into VPCs.

DX is not highly available or encrypted.

It is possible to run VPN over public VIF running over
Direct Connect connection.


DX Locations

Procedure:

. You complete Direct Connect request
. AWS provisions a port
. You download LOA - Letter of authorization - which
  allows you to arrange physical connection between AWS and yourself

=== Choosing between VPN and DX

VPN:

* urgent need - can be deployed in minutes
* cost constrained - cheap
* low end or consumer hardware - DX requires BGP
* encryption required
* flexibility to change locations
* highly available options available
* short-term connectivity

Direct Connect:

* Higher throughput
* consistent performance (throughput)
* consistent low latency
* large amounts of data - cheaper than VPN for higher volume
* no contention with existing internet connection

Both:

* VPN as cheaper HA option for DX
* VPN as an additional layer of HA (in addition to two DX)
* if some form of connectivity is needed immediately,
  provides it before the DX connection is live
* can be used to add encryption over the top of a DX (public VIF VPN)

=== Snow products

Used when you have huge amount of data.

* snowball
* snowball edge
* snowmobile

Snowball:

* can be used for **in** or **out** jobs.
* log a job and an empty device or device with data is shipped
* ideal for TB or PB data transfers - 50 TB or 80 TB capacity per Snowball
* 1Gbps (RJN5 1Gbase-TX) or 10Bbps (LR/SR) using a SFP
* data encryption using KMS
* generally used from 10 TB -> 10 PB (the economical range)
* larger jobs or multiple locations can use multiple Snowballs
* end-to-end proces time is low for the amount of data (i.e., week(s))

Other options:

* direct transfer to S3
* storage gateway

Connectivity options:

* Snowball client
* AWS S3 adapter - to use as

Snowball Edge:

* includes both storage and compute
* larger capacity
* 10 Gbps (RJ45), 10/25 Gbps (SFP), 45/50/100 Gbps (QSFP+)
* compute can be used for local instances or Lambda functionality
* three versions:
  ** edge storage optimized: 80TB, 24 vCPU, 32 GiB RAM
  ** edge compute optimized: 100 TB + 7.68 TB NVMe, 52 vCPUs, and 208 GiB RAM
  ** edge compute optimized with GPU - as above with a GPU equivalent to P3 EC2 instance
* compute can be used for local IoT, for data processing prior to ingestion into AWS, and much more
* used in the same type of situations as Snowballs but when compute is required

Snowmobile:

* portable storage data center within a shipping container on a semi-truck
* available in certain areas via special order from AWS
* used when single location is 10 PB+ is required
* each snowmobile can transfer up to 100 PB
* not economical for sub 10 PB and where multiple locations are required
* situated on-site and connected into your data center for
  the duration of transfer

=== Storage gateway

Storage gateway is a hybrid storage service that allows you to migrate data int AWS, extending yoru on-premises strage capacity using AWS.

Storage gateway types:

* file gateway - store files as objects in S3, with a local cache for low-latency access to your
  most recently used data
  ** presents its storage as SMB shares
* volume gateway - block storage in S3 with point-in-time backups as Amazon EBS snapshots.
  ** you create access volumes
  ** access volumes accesible by iSCSI
  ** iSCSI is generally used with NAS or SAN products
  ** types:
    *** gateway stored volumes - all the data stored on the gateway itself and snapshots are taken into AWS
    *** gateway cached volums - primary source of data is inside AWS, that data is cached at the gateway
* tape gateway (VTL - virtual tape library) - back up your data to S3 and archive in Amazon Glacier using
  your existing tape-based processes
  ** present VTL over iSCSI to any compatible backup software
  ** high admin overhead

Storage gateway is a virtual appliance.

=== Database Migration Service

AWS DMS is a service to migrate relational database.

It can migrate **to** and **from** any locations with network connectivity to AWS.

* DMS is compatible with: Oracle, MS SQL, MySQL, MariaDB,
  PostgreSQL, MongoDB, SAP.
* data can be synced to most of the above engines, as well
  as Redshift, S3 and DynamoDB.
* you can also use the Schema Conversion Tool (AWS SCT) to transform
  between different database engines as part of a migration.

Components:

* source
* source endpoint
* replication instance (contains replication task)
* destination edpoint
* destination

Scenarios:

* scaling database resources **up** or **down** without downtime
* migrating databases from on-premises to AWS, from AWS to on-premises,
  or **to/from** other cloud platforms.
* moving data between different DB engines, including schema conversion
* partial/subset data migration
* migration with little to no admin overhead, as a service

== Identity federation

Identity federation (IDF) is an architecture where identities of an external
identity provider (IDP) are recognized.

Single sign-on (SSO) is where credentials of an external identity are used to allow
access to a local system (e.g. AWS).

Types of IDF include:

* **cross-account roles**: a remote account (IDP) is allowed to assume
  a role and access your account's resources
* **SAML 2.0 IDF**: an on-premises or AWS-hosted directory service
  instance is configured to allow Active Directory users to log in to the
  AWS console.
* Web Identity Federation: IDPs such as Google, Amazon, and Facebook
  are allowed to assume roles and access resources in your account

**Cognito** and the **Secure Token Service** (**STS**) are used for
IDF.

A federated identity is verified using an external IDP and by proving
the identity (using a token or assertion of some kind) is allowed
to swap that ID for temporary AWS credentials by assuming a role.

=== Reasons to use Identity Federation

**Enterprise access to AWS Resources**:

* users/staff have an existing pool of identities
* you need those identities to be used across all enterprise
  systems including AWS
* access to AWS resources using SSO
* potentially tens or hundreds of thousands of users - more than IAM
  can handle
* you might have an ID team within your business

**Mobile and Web Applications**:

* mobile or web application requires access to AWS resources
* you need a certain level of guest access - and extra once logged in
* customers have other identities - Google, Twitter, Facebook,
  etc. - and need to use those
* you don't want credentials stored within the application
* could be millions of more users - beyond the capabilities of IAM
* customers might have multiple third-party logins, but
  they represent one real person

**Centralized Identity Management (AWS Accounts)**:

* tens of hundreds of AWS accounts in an organization
* need central store of IDs - either IAM or an external provider
* role switching used from an ID account into member accounts

== Application integration services

=== SNS - Simple Notification Service

Topic - you send notifications to the topic.

Subscriber - the receiver.

* SNS coordinates and manages the sending and delivery of messages.
* Messages sent to a topic are delivered to subscribers.
* SNS is integrated with many AWS services and can be used
  for certain event notifications (e.g., CloudFormation stack creation)
* using SNS, CloudWatch notify admins of important alerts
* SNS can be used for mobile push notifications

SNS components:

* Topic
    ** an isolated configuration for SNS, including permissions
        *** messages (<= 256 kB) are sent to a topic
        *** subscribers to that topic receive messages
* Subscriber
    ** endpoints that receive messages for a topic
        *** HTTP(s)
        *** email and email-JSON
        *** SOS (message can be added to one or more queues)
        *** mobile push notifications (iOS, Android, Amazon, MS)
        *** lambda functions (function invoked)
        *** SMS (cellular message)
* Publisher
    ** an entity that publishes/sends messages to queues
        *** application
        *** aws services, including S3 (S3 events), CloudWatch,
            CloudFormation, etc.

Supports encryption in transit and at rest.

=== SQS - Simple Queue Service

* message queues for inter-process/server/service messaging
* SQS is used mainly to create decoupled architectures
* messages are added to a queue and retrieved via polling

Polling types:

* short polling - available messages are returned ASAP
  ** a short poll might return 0 messages.
  ** causes increases number of API calls
* long polling - waits for messages for a given WaitTimeSeconds
  ** more efficient - less empty API calls

Types of queues:

* standard queues
* fifo queues

Each SQS message contains up to 256 kB.

Can link data stored in S3 for larger payloads.

When a message is polled, it is hidden in the queue.

It can be deleted when processing is completed - otherwise,
after a __VisibilityTimeout__ period, it will return
to the queue.

Queues can be configured with a __maxReceiveCount__,
allowing  messages that are failing to be moved to a dead-letter queue.

Lambda functions can be invoked based on messages on a queue
offering better scaling and faster response than Auto Scaling
groups for any messages that can be processed quickly.

Standard queues:

* nearly unlimited throughput
* order not quaranteed
* messages ar e guaranteed to be delivered at least once,
  but sometimes more than once

FIFO queues:

* first-in, first-out
* mesages are delivered once - duplicates do not occur
* max 3k messages per second witch batching
* max 300 messages per second without batching

VisibilityTimeout - 0 secs to 12 hours (default 30 seconds)

MessageRetentionPeriod - 16 seconds to 14 days, default 4 days

You use receipt handle when deleting message from the queue.

[source,bash]
----
aws sqs get-queue-attributes --queue-url https://URL --attribute-names All

aws sqs send-message --queue-url https://URL --message-body "INSERTMESSAGE"

aws sqs receive-message --wait-time-seconds 10 --max-number-of-messages 10 --queue-url https://URL

aws sqs --region us-east-1 receive-message --wait-time-seconds 10 --max-number-of-messages 10 --queue-url https://URL

aws sqs delete-message --queue-url https://URL --receipt-handle "INSERTHANDLE"
----

=== Elastic Transcoder

Converts media files.

Billed a per-minute charge while using the service.

A pipeline is a queue for jobs:

* stores source and destination settings, notification, security, and other high settings
* jobs processed in the ordder they are added as resources allow.

Job:

* defines the input object and up to 30 output objects/formats
* added to a pipeline in the same region and use the buckets defined
  in the pipeline for input/output

Presets contain transcoding settings.

Pipeline settings:

* name
* input bucket
* IAM role
* output bucket for transcoded files and playlists
* output bucket for thumbnails
* notifications:
  ** on progressing
  ** on warning
  ** on completion
  ** on error


== Todo list

* Route table's route propagation and Virtual Private Gateways
* Read Well architecture framework whitepaper.
* Websockets:
    ** https://docs.aws.amazon.com/apigateway/latest/developerguide/welcome.html
    ** https://tools.ietf.org/html/rfc6455
* S3 permissions: https://aws.amazon.com/blogs/security/iam-policies-and-bucket-policies-and-acls-oh-my-controlling-access-to-s3-resources/
* CORS: https://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html
* Storage classes: https://aws.amazon.com/s3/storage-classes/
* https://docs.aws.amazon.com/AmazonS3/latest/user-guide/restore-archived-objects.html
* databases:
  ** https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithParamGroups.html
  ** https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_WorkingWithOptionGroups.html
  ** https://aws.amazon.com/rds/mysql/pricing/
  ** https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/UsingWithRDS.IAM.html
  ** https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Limits.html
  ** https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html
  ** https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/putty.html
* Multi-AZ RDS: https://aws.amazon.com/rds/details/multi-az/
* Aurora serverless: https://docs.aws.amazon.com/AmazonRDS/latest/AuroraUserGuide/aurora-serverless.setting-capacity.html
* Identity federation:
  ** https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRole.html
  ** https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRoleWithSAML.html
  ** https://docs.aws.amazon.com/STS/latest/APIReference/API_AssumeRoleWithWebIdentity.html




Questions: what is the pricing of NAT Gateways?
