= Kubernetes
:doc-root: https://notes.jdata.pl
:toc: left
:toclevels: 4
:tabsize: 4
:docinfo1:

docker-compose.yml

[source]
----
pg:
    image: postgres:9.4
frontend:
    image: nginx
    links:
        -pg
----

Another docker-compose.yml:

[source]
----
pg:
    image: postgres
api:
    restart: on-failure
    build: ./api
    volumes:
        - ./api:/app
    command: "--reload"
    links:
        - pg
    ports:
        - "8000:8000"
apiambassador:
    image: cpuguy83/docker-grand-ambassador
    volumes: /var/run/docker.sock:/var/run/docker.sock
    command: -name=chapter2_api_1
frontend:
    image: nginx
    volume:
        - ./frontend/nginx.conf:/etc/nginx/nginx.conf
    linx:
        - apiambassador:api
    ports:
        - "80:80"
----

An ambassador container is a container that stands in front of another one.

== What is Kubernetes

* runs docker containers
* labeling system for control
* spans many physical machines
* runs google container engine

.Pods:

* atomic unit of control
* set of running docker containers (often only one)
* containers "think" theyâ€™re running on the same machine
* always on the same host

.Replication controller (RC):

* manages pods
* tries to maintain a number of matching pods
* matches using labeling system

.Replication controller properties:

* count
* name
* version

.Services:

* DNS
* load balancer (set of pods comes from label matching)

=== Download kubernetes

Download latest stable release from https://github.com/kubernetes/kubernetes/releases

Open up cluster/aws/config-default.sh with editor

 $ KUBERNETES_PROVIDER=aws cluster/kube-up.sh

What that did:

* new VPC: 172.20.0.*
* 5 EC2 instances (master + 4 minions), with public IPs
* ASG for minions
* SSH keys for direct access
    ** ~/.ssh/kube_aws_rsa
* kubectl is configured:
    ** ~/.kube/config

=== Kubernetes service

* Service
* Endpoints

[source]
----
kind: Service
apiVersion: v1
metadata:
    name: database
spec:
    ports:
        - port: 5432
kind: Endpoints
apiVersion: v1
metadata:
    name: database
subnets:
    - addresses:
        - ip: 172.20.2.118
    ports:
        - port: 5432
----

 $ kubectl create -f database.yml

 $ kubectl describe svc database

== Kubernetes Essentials (linuxacademy course)

* kube master
    ** docker
    ** kubeadm - automates proces of setting up new
       kubernetes cluster
    ** kubelet - agent
    ** kubectl - command line tool
    ** control plane
* kube node
    ** docker
    ** kubeadm
    ** kubelet
    ** kubectl

Installing docker on nodes:

[source,bash]
----
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

sudo add-apt-repository    "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
   $(lsb_release -cs) \
   stable"

sudo apt-get update

sudo apt-get install -y docker-ce=18.06.1~ce~3-0~ubuntu

#disabling automatic updating of docker-ce
sudo apt-mark hold docker-ce
----

Installing Kubernetes:

[source,bash]
----
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

cat << EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF

sudo apt-get update

sudo apt-get install -y kubelet=1.12.2-00 kubeadm=1.12.2-00 kubectl=1.12.2-00

sudo apt-mark hold kubelet kubeadm kubectl
----

=== Starting kubernetes

On master node:

[source,bash]
----
sudo kubeadm init --pod-network-cidr=10.244.0.0/16
----

In the output there are commands to start using the cluster,
and the command to join worker nodes to the cluster.

[source,bash]
----
$  mkdir -p $HOME/.kube
$  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
$  sudo chown $(id -u):$(id -g) $HOME/.kube/config
----

[source,bash]
$ kubectl version

Join worker nodes by `kubeadm join` command (printed out when
creating the cluster on master node).

Example command:

[source,bash]
kubeadm join 10.0.1.101:6443 --token it91jf.1aj6f37ldkax1hab --discovery-token-ca-cert-hash sha256:9f56f3fc017355d3e19deec3621c434becb894c4523c8768833df238a757685a

Check the nodes are connected by:

[source,bash]
$ kubectl get nodes

=== Configuring networking with Flannel

On all nodes:

[source,bash]
----
$ echo "net.bridge.bridge-nf-call-iptables=1" | sudo tee -a /etc/sysctl.conf
$ sudo sysctl -p
----

On master node:

[source,bash]
----
$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/bc79dd1505b0c8681ece4de4c0d86c5cd2643275/Documentation/kube-flannel.yml

$ kubectl get nodes

$ kubectl get pods -n kube-system
----

=== Basic concepts

==== Pods

Pods are the smallest and most basic building blocks of the
Kubernetes model.

A pod consists of one or more containers, storage resources,
and a unique IP address in the Kubernetes cluster network.

Create a simple pod:

[source,bash]
----
cat << EOF | kubectl create -f -
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx
EOF
----

Commands:

[source,bash]
----
$ kubectl get pods

$ kubectl get pods -n kube-system

$ kubectl describe pod nginx

$ kubectl delete pod nginx
----

==== Clustering and nodes

[source,bash]
kubectl describe node $node_name

Creating a deployment:

[source,bash]
----
cat << EOF | kubectl create -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.15.4
        ports:
        - containerPort: 80
EOF
----

Create busybox pod for testing:

[source,bash]
----
cat << EOF | kubectl create -f -
apiVersion: v1
kind: Pod
metadata:
  name: busybox
spec:
  containers:
  - name: busybox
    image: radial/busyboxplus:curl
    args:
    - sleep
    - "1000"
EOF
----

Testing:

[source,bash]
----
$ kubectl get pods -o wide

$ kubectl exec busybox -- curl $nginx_pod_ip
----

=== Kubernetes Deployments

Deployments allow to specify a desired state for a set
of pods.
The cluster will then constantly work to maintain that
desired state.

* scaling up and down
* rolling updates
* self-healing

==== Kubernetes architecture and components

The control plane components:

* etcd - distributed synchronized data storage
* kube-apiserver - serves the Kubernetes API,
  the primary interface for the cluster
* kube-controller-manager - bundles several components
  into one package.
* kube-scheduler - when to run pods and on which nodes

In addition to control plane each node also has:

* kubelet - an agent that executes containers
* kube-proxy - handles network communication between nodes
  by adding firewall routing rules

Creating a simple deployment:

[source,bash]
----
cat <<EOF | kubectl create -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.15.4
        ports:
        - containerPort: 80
EOF
----

[source,bash]
----
$ kubectl get deployments

$ kubectl describe deployment nginx-deployment
----

==== Kubernetes services

Services allow to dynamically access a group of replica pods.

[source,bash]
----
cat << EOF | kubectl create -f -
kind: Service
apiVersion: v1
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 80
    targetPort: 80
    nodePort: 30080
  type: NodePort
EOF
----

[source,bash]
----
$ kubectl get svc
----

==== Microservices

Microservices benefits:

* scalability - can be independly scalable
* cleaner code - easier changes
* reliability - problems in one area of the application
  are less likely to affect other areas.
* variety of tools - you can use different languages for
  different parts of the application

Sample robot-shop app:

[source,bash]
$ git clone https://github.com/linuxacademy/robot-shop.git

[source,bash]
----
$ kubectl create namespace robot-shop
$ kubectl -n robot-shop create -f ~/robot-shop/K8s/descriptors
----

== From start

=== Starting the cluster

 $ kubeadm config images pull

 $ sudo kubeadm init --pod-network-cidr=10.244.0.0/16

 $ mkdir ~/.kube
 $ sudo cp /etc/kubernetes/admin.conf ~/.kube/config
 $ sudo chown $(id -u):$(id -g) $HOME/.kube/config

 $ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/v0.10.0/Documentation/kube-flannel.yml

 $ kubectl get pods --all-namespaces

 $ sudo kubeadm join 172.31.99.111:6443 --token 0wso1u.vxe0tt68vv0bshqj --discovery-token-ca-cert-hash sha256:c2a44af9e5182df3c35ab9c4e1811ad77e591ba5036991cd17c2ab9ce1370979

 $ kubectl get nodes

.Node types:
* master node
    ** kube-apiserver
        *** etcd
        *** kube-scheduler
        *** cloud-controller-manager
        *** kube-controller-mamager
* worker node
    ** kubelet
    ** kube proxy
    ** pod
        *** container

=== Debian Install From Scratch

.Ports (all are TCP ports):

[cols="^2,^2,<10",options="header"]
|======
|node type     |ports        |usage

.6+|master     |6443         |Kubernetes API server
               |2379-2380   <|etcd server client API
               |10250       <|Kubelet API
               |10251       <|kube-scheduler
               |10252       <|kube-controller-manager
               |10255       <|Read-Only Kubelet API
.3+|worker     |10250        |Kubelet API
               |10255       <|Read-Only Kubelet API
               |30000-32767 <|NodePort Services
|======

 $ sudo -i
 $ sudo apt install docker.io -y

./etc/docker/daemon.json
[source]
{
    "exec-opts": ["native.cgroupdriver=systemd"]
}

 $ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

./etc/apt/sources.list.d/kubernetes.list
[source]
deb http://apt.kubernetes.io/ kubernetes-xenial main

 $ sudo apt update && sudo apt upgrade -y

 $ sudo apt install -y kubelet kubeadm kubectl

 $ sudo kubeadm init --pod-network-cidr=10.244.0.0/16

Exit the root shell

 $ mkdir $HOME/.kube
 $ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
 $ sudo chown $(id -u):$(id -g) $HOME/.kube/config

 $ kubectl get pods --all-namespaces

 $ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/v0.10.0/Documentation/kube-flannel.yml

==== Creating worker nodes

 $ sudo apt install docker.io -y

./etc/docker/daemon.json
[source]
{
    "exec-opts": ["native.cgroupdriver=systemd"]
}

 $ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

./etc/apt/sources.list.d/kubernetes.list
[source]
deb http://apt.kubernetes.io/ kubernetes-xenial main

 $ sudo apt update && sudo apt upgrade -y

 $ sudo apt install -y kubelet kubeadm kubectl

 $ kubeadm join ...

=== Installing on RedHat

.swap off:

 $ sudo swapoff -a

Remove swap from `/etc/fstab

 $ sudo yum update -y

 $ sudo yum -y install docker

 $ sudo systemctl enable docker

 $ sudo systemctl start docker

[source]
----
cat <<EOF > /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64
enabled=1
gpgcheck=1
repo_gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
EOF
----

 $ sudo setenforce 0

.edit /etc/selinux/config

 SELINUX=permissive

 $ sudo yum install -y kubelet kubeadm kubectl

 $ sudo systemctl enable kubelet

 $ sudo systemctl start kubelet

[source]
----
cat <<EOF >  /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
----

 $ sudo sysctl --system

 $ sudo kubeadm init --pod-network-cidr=10.244.0.0/16

 $ mkdir -p $HOME/.kube
 $ sudo cp /etc/kubernetes/admin.conf $HOME/.kube/config
 $ sudo chmod $(id -u):$(id -g) config

 $ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/v0.10.0/Documentation/kube-flannel.yml


=== Container networking

* CNM - Container Network Model
* CNI - Container Network Interface

==== Container Network Model

Specification proposed by Docker.

Adopted by libnetwork

.Native Dorker drivers:
* none
* bridge
* overlay

`Libnetwork` is the canonical implementation of the CNM specification.

include::kubernetes-certified-kubernetes-adm.adoc[]
